import argparse
import cv2, os, glob
from collections import OrderedDict
import torch
import torch.nn as nn
from torch.nn import functional as F
import numpy as np
import matplotlib.pyplot as plt
from maskrcnn_benchmark.config import cfg

import maskrcnn_benchmark.engine.post_process as util
from copy import deepcopy

from scipy import interpolate
from tqdm import tqdm
import logging

from maskrcnn_benchmark.utils.comm import synchronize, get_rank

#def get_imgs(idx):
#    return cv2.imread(test_imgs[idx])

### input line: [[x0, x1...],...], [[y0, y1...]...]
### output: list[lines_info]
def create_polyline_for_lines(in_x, in_y):
    lines_info = list()
    for i, (xl, yl) in enumerate(zip(in_x, in_y)): # for x/y list of each line
        if len(yl) <= 1:
            continue # drop 1 point line
        
        # ??? merge_point_with_same_y(yl,xl)
        
        y_max, y_min = max(yl), min(yl)

        yl, xl = np.array(yl), np.array(xl)
        ind = np.argsort(yl) # small->big
        yl, xl = yl[ind], xl[ind]

        pt_lower = np.array([ xl[-1], yl[-1] ])
        pt_upper = np.array([ xl[0], yl[0] ])
        
        # choose k
        if len(yl) <= 3:
            k = len(yl) - 1
            # print("pts len: {}, thus choose k: {}".format(len(yl), k))
            tck = interpolate.splrep(x=yl, y=xl, s=0, k=k)
        else:
            tck = interpolate.splrep(x=yl, y=xl, s=0)
        
        # create sampled y in range of (y_min, y_max)
        y_sample = g_default_sample[g_default_sample >= y_min]
        y_sample = y_sample[y_sample <= y_max]

        x_sample = interpolate.splev(x=y_sample, tck=tck, der=0)
        lines_info.append({
            'tck': tck,
            'y_max': y_max,
            'y_min': y_min,
            'pt_lower':pt_lower, # bound in lower image
            'pt_upper':pt_upper, # bound in upper image
        })
    return lines_info

# input line: list[lines_info]
# output: cluster of lines' id 
def merge_close_line(lines, thresh=15):
    result = list()
    selected = [False] * len(lines) # [False, ... False]
    for n in range(len(lines)):
        if selected[n]:
            continue
        result.append(list()) # create a new line (contain ids)
        result[-1].append(n)
        selected[n] = True
        for t in range(n + 1, len(lines)):
            if selected[t]:
                continue
            dis = compute_dist(lines[n], lines[t])
            if dis <= thresh: # find close line(t-th) of n-th line
                selected[t] = True 
                result[-1].append(t) # merge t-th lane
    return result


# input line: lines_info
def compute_dist(l1, l2):
    tck1 = l1['tck']
    tck2 = l2['tck']
    upper_bound = max(l1['y_min'], l2['y_min'])
    lower_bound = min(l1['y_max'], l2['y_max'])
    
    if upper_bound >= lower_bound:
        # seprated line
        # print("line seprated in y")
        if l1['y_max'] <= l2['y_min']:
            p1, p2 = l1['pt_lower'], l2['pt_upper']
            dist = np.sqrt(np.sum( (p1 - p2)**2 )) 
            return dist 
        elif l2['y_max'] <= l1['y_min']:
            p1, p2 = l2['pt_lower'], l1['pt_upper']
            dist = np.sqrt(np.sum( (p1 - p2)**2 ))
            return dist
        else:
            print("error")
            return 1e6
    else: 
        # overlaped line
        # print("overlaped line")
        ys_sample = np.arange(upper_bound, lower_bound, step=2.)
        xs_sample1 = interpolate.splev(x=ys_sample, tck=tck1, der=0)
        xs_sample2 = interpolate.splev(x=ys_sample, tck=tck2, der=0)
        dists = np.abs(xs_sample1 - xs_sample2)
        dist_sum = np.sum(dists) / len(ys_sample)
        return dist_sum


def eliminate_out(sorted_x, sorted_y, confidence = None, image = None):
    out_x = []
    out_y = []

    for lane_x, lane_y in zip(sorted_x, sorted_y):
        
        if len(lane_y) < 3:
            out_x.append(lane_x)
            out_y.append(lane_y)
            continue

        lane_x_along_y = np.array(deepcopy(lane_x))
        lane_y_along_y = np.array(deepcopy(lane_y))

        ind = np.argsort(lane_x_along_y, axis=0)
        lane_x_along_x = np.take_along_axis(lane_x_along_y, ind, axis=0)
        lane_y_along_x = np.take_along_axis(lane_y_along_y, ind, axis=0)
        
        if lane_y_along_x[0] > lane_y_along_x[-1]: #if y of left-end point is higher than right-end
            starting_points = [(lane_x_along_y[0], lane_y_along_y[0]), 
                               (lane_x_along_y[1], lane_y_along_y[1]), 
                               (lane_x_along_y[2], lane_y_along_y[2]),
                                (lane_x_along_x[0], lane_y_along_x[0]), 
                               (lane_x_along_x[1], lane_y_along_x[1]), 
                               (lane_x_along_x[2], lane_y_along_x[2])] # some low y, some left/right x
        else:
            starting_points = [(lane_x_along_y[0], lane_y_along_y[0]), 
                               (lane_x_along_y[1], lane_y_along_y[1]), 
                               (lane_x_along_y[2], lane_y_along_y[2]),
                                (lane_x_along_x[-1], lane_y_along_x[-1]), 
                               (lane_x_along_x[-2], lane_y_along_x[-2]), 
                               (lane_x_along_x[-3], lane_y_along_x[-3])] # some low y, some left/right x            
    
        temp_x = []
        temp_y = []
        for start_point in starting_points:
            temp_lane_x, temp_lane_y = generate_cluster(start_point, lane_x, lane_y, image)
            temp_x.append(temp_lane_x)
            temp_y.append(temp_lane_y)
        
        max_lenght_x = None
        max_lenght_y = None
        max_lenght = 0
        for i, j in zip(temp_x, temp_y):
            if len(i) > max_lenght:
                max_lenght = len(i)
                max_lenght_x = i
                max_lenght_y = j
        out_x.append(max_lenght_x)
        out_y.append(max_lenght_y)

    return out_x, out_y

# image is useless
def generate_cluster(start_point, lane_x, lane_y, image = None):
    cluster_x = [start_point[0]]
    cluster_y = [start_point[1]]

    point = start_point
    while True:
        points = util.get_closest_upper_point(lane_x, lane_y, point, 3)
         
        max_num = -1
        max_point = None

        if len(points) == 0:
            break
        if len(points) < 3:
            for i in points: 
                cluster_x.append(i[0])
                cluster_y.append(i[1])                
            break
        for i in points: 
            num, shortest = util.get_num_along_point(lane_x, lane_y, point, i, image)
            if max_num < num:
                max_num = num
                max_point = i

        total_remain = len(np.array(lane_y)[np.array(lane_y) < point[1]])
        cluster_x.append(max_point[0])
        cluster_y.append(max_point[1])
        point = max_point
        
        if len(points) == 1 or max_num < total_remain/5:
            break

    return cluster_x, cluster_y


def merge_point_with_same_y(in_x, in_y):
    new_in_x, new_in_y = list(), list()

    for lid, (xl, yl) in enumerate(zip(in_x, in_y)):
        new_xl, new_yl = list(), list()
        selected = [False] * len(yl)

        for i in range(len(yl)):
            if selected[i]:
                continue # ignore visited or merged point
            xi_sum = xl[i]
            xi_cnt = 1
            selected[i] = True

            for j in range(i+1, len(yl)):
                if selected[j]: # ignore merged point
                    continue
                if yl[j] == yl[i]: # merge this point
                    selected[j] = True
                    xi_sum += xl[j]
                    xi_cnt += 1
            new_yl.append(yl[i])
            new_xl.append(xi_sum / xi_cnt)
        if len(new_yl) <= 1:
            continue # ignore 1 point line
        new_in_x.append(new_xl)
        new_in_y.append(new_yl)
    return new_in_x, new_in_y


### input: lines[ line[ pt[x,y]... ]... ] and points sorted along y
def remove_close_points(lines):
    xls = [[pt[0] for pt in line] for line in lines]
    yls = [[pt[1] for pt in line] for line in lines]
    
    xls, yls =merge_point_with_same_y(xls, yls)
    
    new_lines = list()
    for xl, yl in zip(xls, yls):
        if len(yl) <=2: # drop 2 points line
            continue
        
        if len(yl) <= 3:
            k = len(yl) - 1
            tck = interpolate.splrep(x=yl, y=xl, s=0, k=k)
        else:
            tck = interpolate.splrep(x=yl, y=xl, s=0)

        new_line = list()
        y_min, y_max = yl[0], yl[-1]
        if (y_max - y_min) <= 3.:
            ys_sample = np.array([y_min, y_max])
        else:
            ys_sample = np.arange(y_min, y_max, step=3.)

        xs_sample = interpolate.splev(x=ys_sample, tck=tck, der=0)
        new_line = [[x*g_rx, y*g_ry] for x,y in zip(xs_sample, ys_sample)]
        new_lines.append(new_line)
    return new_lines



def post_proc(img_id, prediction):
    outlines = list()
    ### 1. drop points outside of anchor region(32x32)
    for i, line_candidates in enumerate(prediction):
        outline = list()
        for l in line_candidates: # for candidates of a line
            line = l.lane
            if len(line) <= 1: # drop 1 point line
                continue
            ax,ay = l.ax,l.ay
            bound_x = [(ax-g_stride), (ax+g_stride)]
            bound_y = [(ay-g_stride), (ay+g_stride)]
            for pt in line:
                x = int(pt.x)
                y = int(pt.y)
                if x > bound_x[0]  and x < bound_x[1] and y > bound_y[0] and y < bound_y[1]: 
                    if x >= .0 and y >= .0 and x <= 511. and y <= 255.:
                        outline.append([pt.x, pt.y])
        outlines.append(outline)
    
    ### 2.
    x_lines = [[pt[0] for pt in line] for line in outlines]
    y_lines = [[pt[1] for pt in line] for line in outlines]
    ### 2.1 eliminate outlier
    in_x, in_y = util.sort_along_y(x_lines, y_lines)  
    in_x, in_y = eliminate_out(in_x, in_y)
    ### 2.2 merge point with same y
    in_x, in_y = merge_point_with_same_y(in_x, in_y)

    ### 3. merge close line
    ### 3.1 create polyline for each line
    lines_info = create_polyline_for_lines(in_x, in_y)

    ### 3.2 find and merge close line
    lid_cluster = merge_close_line(lines_info)
    # output lines format lines[line[point[x,y],...],...]
    regrouped_lines = list()
    for i, lids in enumerate(lid_cluster):
        temp = list()
        for lid in lids:
            xl, yl = in_x[lid], in_y[lid]
            temp.extend([[x, y] for x, y in zip(xl, yl)])
        # sort along y
        temp = sorted(temp, key=lambda pt: pt[1])
        regrouped_lines.append(temp)

    ### 4. remove close points
    # print(regrouped_lines)
    # print("\n")
    final_lines = remove_close_points(regrouped_lines)
    # print(final_lines)
    return final_lines

color = [(255,0,0), (0,255,0),(0,0,255),\
         (255,255,0),(255,0,255),(0,255,255),(255,255,255),\
         (100,255,0),(100,0,255),(255,100,0),(0,100,255),(255,0,100),(0,255,100),(0,0,0)]


def get_color(i):
    m = len(color)
    return color[i] if i < m else color[i%m]


def img_write(img_id, lines):
    img = cv2.imread(g_test_imgs[img_id])
    for i, line in enumerate(lines):
        for pt in line:
            cv2.circle(img, ( int(pt[0]), int(pt[1]) ), 3, get_color(i), -1)
    img_path = os.path.join('out_img', 'pred_' + str(img_id) + '.png')
    cv2.imwrite(img_path, img)






parser = argparse.ArgumentParser(description="")
parser.add_argument("--local_rank", type=int, default=0)
parser.add_argument("--gpu_beg", type=int, default=9)
parser.add_argument("--gpu_cnt", type=int, default=1)
args = parser.parse_args()

distributed = num_gpus > 1
if distributed:
    torch.cuda.set_device(args.local_rank)
    torch.distributed.init_process_group(
        backend="gloo", init_method="env://"
    )
    synchronize()


#cfg.merge_from_file('e2e_mask_rcnn_R_50_FPN_1x.yaml')
DEBUG = False # True
if DEBUG:
    pth_file = "exp/oct20/inference/aicom_lane_test/debug01.pth"
else:
    pth_file = "exp/oct20/inference/aicom_lane_test/results.pth"
outputs_dict = torch.load(pth_file, 
                          map_location=torch.device("cpu"))
predictions = outputs_dict["predictions"]
g_test_imgs = outputs_dict["test_images"]
### global paramter
g_rx, g_ry = 1280/512., 720/256.
g_stride = 16.
g_default_sample = np.arange(0., 256., step=3.)

final_res = list()
for i, (img_id, pred) in enumerate( tqdm( predictions.items() ) ):
    
    final_lines = post_proc(img_id, pred)
    final_res.append({ img_id: final_lines })

    # create image
    if DEBUG:
        img_write(img_id, final_lines)
    if i % 1000 == 0:
        img_write(img_id, final_lines)

    #if DEBUG and i == 2:
    #    print("Debug done.")
    #    break
if DEBUG:
    torch.save(final_res, "result_debug.pth")
else:
    torch.save(final_res, "result.pth")